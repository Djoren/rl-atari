{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.losses import Huber, CategoricalCrossentropy, KLDivergence\n",
    "\n",
    "import sys\n",
    "sys.path.append('../script')\n",
    "from utils import ( \n",
    "    preprocess_frame_v4, choose_action, get_lin_anneal_eps, sample_ran_action, \n",
    "    EpisodeLogger, frame_max_pooling, FRAME_CROP_SETTINGS, animate_episode_sal\n",
    ")\n",
    "from atari_model import (\n",
    "    atari_model, atari_model_dueling, atari_model_dueling, atari_model_distr,\n",
    "    fit_batch_DDQNn_PER, fit_batch_DDQNn_PER_DS\n",
    ")\n",
    "from replay_memory import PrioritizedReplayMemory, UniformReplayMemory\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration\n",
    "game = 'space_invaders'\n",
    "total_train_len = 50_000      # Total no. of episodes to train\n",
    "max_episode_len = None        # Max no. of frames agent is allowed to see per episode [CURRENTLY UNUSED]\n",
    "state_len = 4                 # No. of stacked frames that comprise a state\n",
    "train_interval = 4            # Every x actions a gradient descend step is performed\n",
    "tgt_update_interval = 10_000  # Interval in terms of no. of frames after we update target model weights\n",
    "eps_init = 1                  # Initial eps in eps-greedy exploration \n",
    "eps_final = 0.1               # Final eps in eps-greedy exploration\n",
    "eps_final_frame = 1_000_000   # No. of frame over which eps is linearly annealed to final eps\n",
    "replay_init_sz = 50_000       # Replay mem. initialization size: random policy is run for this many frames, training starts after\n",
    "replay_mem_sz = 1_000_000     # Max no. of frames cached in replay memory\n",
    "\n",
    "batch_sz = 32                 # No. of training cases (sample from replay mem.) for each SGD update\n",
    "disc_rate = 0.99              # Q-learning discount factor (gamma)\n",
    "n_step = 3                    # Determines multi-step learning (n=1 is simply single step learning)\n",
    "# lr = 0.0000625              # Learning rate of CNN\n",
    "lr = 0.00025                  # Learning rate of CNN\n",
    "\n",
    "per_alpha = 0.5               # Exponent of priority probabilities\n",
    "per_beta = 0                  # Exponent of importance sampling weights # TODO: amend code to handle [0.4, 1] \n",
    "init_tds = False              # Whether to compute td-errors for initial replay memories\n",
    "crop_frame = True\n",
    "\n",
    "# Model variants (Rainbow)\n",
    "large_net = False\n",
    "double_learn = False\n",
    "per_memory = True\n",
    "duel_net = False\n",
    "noisy_net = False\n",
    "distr_net = False\n",
    "kl_loss = False  # For distr net only\n",
    "\n",
    "if noisy_net:\n",
    "    eps_init = eps_final = 0\n",
    "    \n",
    "if distr_net:\n",
    "    N = 51  # No. of atoms for our discretized distr.\n",
    "    V_min, V_max = -10, 100  # Min and max of distribution support\n",
    "    Z = np.linspace(V_min, V_max, N)  # Value distribution (i.e. the atoms)\n",
    "    dZ = (V_max - V_min) / (N - 1)\n",
    "    Z_repN = np.repeat([Z], N, axis=0)  # Utility matrix to avoid recomputing later on\n",
    "    loss = KLDivergence() if kl_loss else CategoricalCrossentropy()\n",
    "else:\n",
    "    Z = None\n",
    "    loss = Huber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging and storage\n",
    "# model_name = 'DQN_cp_4f_50ri_3n_pr_cf_tf7_cc_dd_pp3_ds'\n",
    "model_name = 'del'\n",
    "model_dir = f'../{game}/model/{model_name}'\n",
    "\n",
    "os.mkdir(model_dir)\n",
    "os.mkdir(model_dir + '/record')\n",
    "os.mkdir(model_dir + '/model')\n",
    "\n",
    "opath_mem = f'{model_dir}/replay_mem.pkl'\n",
    "opath_model = f'{model_dir}/model/model.keras'\n",
    "ep_log = EpisodeLogger(model_dir + '/episode_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Atari environment\n",
    "env = gym.make('SpaceInvadersDeterministic-v4')\n",
    "\n",
    "# Set seeds\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = range(6)  # Use default action space https://www.gymlibrary.dev/environments/atari/space_invaders/\n",
    "M = len(action_space)\n",
    "kernel_init = 'he_normal'\n",
    "\n",
    "# Set frame crop configuration\n",
    "env.reset()\n",
    "frame = env.step(1)[0]\n",
    "crop_lims = FRAME_CROP_SETTINGS[game] if crop_frame else None\n",
    "frame_shape = preprocess_frame_v4(frame, crop_lims).shape\n",
    "state_shape = (*frame_shape, state_len)\n",
    "\n",
    "# Initialize behavioral network\n",
    "# If using dueling net, we use a seperate action model to back out V and A streams efficiently\n",
    "# Note that this model is clone of behavioral model and points to the same underlying layers\n",
    "if duel_net:\n",
    "    model = atari_model_dueling(M, lr, state_shape, kernel_init, noisy_net, large_net)\n",
    "    model_action = tf.keras.Model(\n",
    "        inputs=[model.get_layer('input_frames').input], \n",
    "        outputs=[model.get_layer('V').output, model.get_layer('A_adj').output]\n",
    "    )\n",
    "elif distr_net:\n",
    "    model = atari_model_distr(N, M, loss, lr, state_shape, kernel_init, noisy_net)\n",
    "    model_action = model\n",
    "else:\n",
    "    model = atari_model(M, loss, lr, state_shape, kernel_init, noisy_net, large_net)\n",
    "    model_action = model\n",
    "\n",
    "# Initialize target network\n",
    "model_tgt = clone_model(model)\n",
    "model_tgt.set_weights(model.get_weights())\n",
    "\n",
    "# Initialize replay memory\n",
    "if per_memory:\n",
    "    replay_mem = PrioritizedReplayMemory(replay_mem_sz, state_len, n_step, per_alpha, per_beta)\n",
    "else:\n",
    "    replay_mem = UniformReplayMemory(replay_mem_sz, state_len, n_step)\n",
    "\n",
    "frame_num = 0\n",
    "max_episode_reward = 0\n",
    "episode_start = 0\n",
    "init_done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=False, show_layer_activations=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mp_pool = mp.Pool(1)\n",
    "t_lastmax = datetime.now()  # Time since last max train score (controls)\n",
    "i_animation = 0  # Used to toggle between saliency types\n",
    "\n",
    "for episode_num in range(episode_start, total_train_len):\n",
    "    # Start a new game (episode)\n",
    "    init_frame = env.reset()\n",
    "    new_life = True\n",
    "    game_over = False\n",
    "\n",
    "    # Keep track of episode figures\n",
    "    episode_reward = 0\n",
    "    episode_train_cnt = 0\n",
    "    episode_frames = []\n",
    "    episode_states = []\n",
    "    episode_actions = []\n",
    "    episode_Qs = []\n",
    "    episode_Vs = []\n",
    "    episode_As = []\n",
    "    episode_pZs = []\n",
    "    episode_losses = []\n",
    "    episode_tderrs = []\n",
    "\n",
    "    # SI specific: skip first 20 frames when new game (40 in total with new-life line)\n",
    "    for _ in range(20):\n",
    "        env.step(0)\n",
    "\n",
    "    # Play episode until game over\n",
    "    while not game_over:\n",
    "        if new_life:\n",
    "            # SI specific: skip first 20 frames when new life\n",
    "            for _ in range(20):\n",
    "                env.step(0)\n",
    "\n",
    "            for _ in range(random.randint(1, 15)):\n",
    "                # Random initialization, to reduce overfitting\n",
    "                frame, _, game_over, info = env.step(sample_ran_action(action_space))\n",
    "            \n",
    "            lives = info['ale.lives']\n",
    "            frame_pp = preprocess_frame_v4(frame, crop_lims)  # Maxpooling not needed for first frame\n",
    "            state = np.stack(state_len * [frame_pp], axis=2)\n",
    "            \n",
    "        # Select action\n",
    "        eps = get_lin_anneal_eps(frame_num - replay_init_sz, eps_init, eps_final, eps_final_frame)\n",
    "        eps = eps if init_done else 1\n",
    "        action, Q, V, A, pZ = choose_action(\n",
    "            model_action, state, action_space, eps, duel_net, distr_net, Z\n",
    "        )\n",
    "        \n",
    "        # Store state and actions variables\n",
    "        episode_frames.append(frame)\n",
    "        episode_states.append(state)\n",
    "        episode_actions.append(action)\n",
    "        episode_Qs.append(Q)\n",
    "        episode_Vs.append(V)\n",
    "        episode_As.append(A)\n",
    "        episode_pZs.append(pZ)\n",
    "        \n",
    "        # Take action and observe transition\n",
    "        prev_frame = frame  # Keep previous frame for max pooling step\n",
    "        frame, reward, game_over, info = env.step(action)\n",
    "        \n",
    "        # Process env response\n",
    "        frame_pp = frame_max_pooling([prev_frame, frame])\n",
    "        frame_pp = preprocess_frame_v4(frame_pp, crop_lims)\n",
    "        state = np.append(state[:, :, 1:], frame_pp[:, :, None], axis=2)\n",
    "        # reward = clip_reward(reward)\n",
    "        new_life = info['ale.lives'] < lives \n",
    "        lives = info['ale.lives']\n",
    "        \n",
    "        # Add new transition to replay memory\n",
    "        transition = (action, reward, game_over or new_life, new_life, frame_pp)  # TODO: inspect game + life\n",
    "        replay_mem.store_memory(transition)\n",
    "                \n",
    "        # Increase transition counters\n",
    "        frame_num += 1\n",
    "        episode_reward += reward\n",
    "        init_done = frame_num >= replay_init_sz  # Is replay initializing done\n",
    "                    \n",
    "        # After init period start replay transitions and train model\n",
    "        if init_done:\n",
    "            \n",
    "            # Train model every train_interval\n",
    "            if frame_num % train_interval == 0:\n",
    "                mini_batch = replay_mem.get_sample(batch_sz)\n",
    "                batch_idxs, mini_batch = mini_batch[-1], mini_batch[:-1]\n",
    "                w_imps = replay_mem.get_imps_weights(batch_idxs) if per_memory else None\n",
    "                \n",
    "                if distr_net:\n",
    "                    batch_td_errs, loss = fit_batch_DDQNn_PER_DS(\n",
    "                        model, model_tgt, action_space, disc_rate, *mini_batch, w_imps, \n",
    "                        Z, Z_repN, dZ, (V_min, V_max), noisy_net, double_learn\n",
    "                    )\n",
    "                else:\n",
    "                    batch_td_errs, loss = fit_batch_DDQNn_PER(\n",
    "                        model, model_tgt, action_space, disc_rate, *mini_batch, \n",
    "                        w_imps, noisy_net, double_learn\n",
    "                    )\n",
    "                \n",
    "                if per_memory:\n",
    "                    replay_mem.update_priorities(batch_idxs, batch_td_errs)\n",
    "\n",
    "                # Is there balance between updating ps and having new ps set to max? will updated ps stand a chance?\n",
    "                episode_train_cnt += 1\n",
    "                episode_losses.append(loss)\n",
    "                episode_tderrs.append(np.mean(batch_td_errs))\n",
    "\n",
    "            # Update target model\n",
    "            if frame_num % tgt_update_interval == 0:\n",
    "                model_tgt.set_weights(model.get_weights())\n",
    "\n",
    "    # Log episode statistics\n",
    "    ep_log.append(\n",
    "        episode_num, episode_train_cnt, frame_num, episode_reward, \n",
    "        episode_actions, episode_Qs, episode_losses, episode_tderrs\n",
    "    )\n",
    "\n",
    "    # Variables to control output frequency\n",
    "    run_anim_reg = episode_num % 1000 == 0\n",
    "    run_anim_max = (episode_reward > max_episode_reward) & (datetime.now() > t_lastmax)\n",
    "    backup_model = episode_num % 250 == 0\n",
    "\n",
    "    # Output episode animation video every 1000 episodes\n",
    "    # Also output episode video if new max score was attained, and time-delta has been met\n",
    "    if run_anim_reg or run_anim_max:\n",
    "        opath_anim = f'{model_dir}/record/{episode_num}_train_{episode_reward}.mp4'\n",
    "        sal_type = 'gcam' if i_animation % 2 else 'sal'\n",
    "\n",
    "        mp_pool.apply_async(animate_episode_sal, args=(\n",
    "            model, episode_states, episode_frames, episode_actions, \n",
    "            episode_Qs, episode_Vs, episode_As, action_space, opath_anim, \n",
    "            duel_net, distr_net, (Z, episode_pZs), sal_type)\n",
    "        )\n",
    "        i_animation += 1\n",
    "        if run_anim_max:\n",
    "            t_lastmax = datetime.now() + timedelta(minutes=30)\n",
    "            max_episode_reward = episode_reward\n",
    "        \n",
    "    # Backup model and replay memory every 250 episodes\n",
    "    # Note: takes a minute or two, so should not be run frequently \n",
    "    if backup_model:\n",
    "        joblib.dump(replay_mem, opath_mem, compress=3)\n",
    "        model.save(opath_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
