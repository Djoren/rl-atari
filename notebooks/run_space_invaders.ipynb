{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.losses import Huber, CategoricalCrossentropy, KLDivergence\n",
    "\n",
    "import sys\n",
    "sys.path.append('../script')\n",
    "from utils import ( \n",
    "    preprocess_frame_v4, choose_action, get_lin_anneal_eps, sample_ran_action, \n",
    "    EpisodeLogger, frame_max_pooling, FRAME_CROP_SETTINGS, animate_episode_sal\n",
    ")\n",
    "from atari_model import (\n",
    "    atari_model, atari_model_dueling, atari_model_dueling, atari_model_distr,\n",
    "    fit_batch_DDQNn_PER, fit_batch_DDQNn_PER_DS\n",
    ")\n",
    "from replay_memory import PrioritizedReplayMemory\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration\n",
    "game = 'space_invaders'\n",
    "total_train_len = 50_000      # Total no. of episodes to train\n",
    "max_episode_len = None        # Max no. of frames agent is allowed to see per episode [CURRENTLY UNUSED]\n",
    "state_len = 4                 # No. of stacked frames that comprise a state\n",
    "train_interval = 4            # Every x actions a gradient descend step is performed\n",
    "tgt_update_interval = 10_000  # Interval in terms of no. of frames after we update target model weights\n",
    "eps_init = 1                  # Initial eps in eps-greedy exploration \n",
    "eps_final = 0.1               # Final eps in eps-greedy exploration\n",
    "eps_final_frame = 1_000_000   # No. of frame over which eps is linearly annealed to final eps\n",
    "replay_init_sz = 50_000       # Replay mem. initialization size: random policy is run for this many frames, training starts after\n",
    "replay_mem_sz = 1_000_000     # Max no. of frames cached in replay memory\n",
    "\n",
    "batch_sz = 32                 # No. of training cases (sample from replay mem.) for each SGD update\n",
    "disc_rate = 0.99              # Q-learning discount factor (gamma)\n",
    "n_step = 3                    # Determines multi-step learning (n=1 is simply single step learning)\n",
    "# lr = 0.0000625              # Learning rate of CNN\n",
    "lr = 0.00025                  # Learning rate of CNN\n",
    "\n",
    "per_alpha = 0.5               # Exponent of priority probabilities\n",
    "per_beta = 0                  # Exponent of importance sampling weights # TODO: amend code to handle [0.4, 1] \n",
    "init_tds = False              # Whether to compute td-errors for initial replay memories\n",
    "crop_frame = True\n",
    "\n",
    "# Model variants (Rainbow)\n",
    "large_net = True\n",
    "double_learn = True\n",
    "duel_net = True\n",
    "noisy_net = False\n",
    "distr_net = False\n",
    "\n",
    "if noisy_net:\n",
    "    eps_init = eps_final = 0\n",
    "    \n",
    "if distr_net:\n",
    "    N = 51  # No. of atoms for our discretized distr.\n",
    "    V_min, V_max = -10, 10  # Min and max of distribution support\n",
    "    Z = np.linspace(V_min, V_max, N)  # Value distribution (i.e. the atoms)\n",
    "    dZ = (V_max - V_min) / (N - 1)\n",
    "    Z_repN = np.repeat([Z], N, axis=0)  # Utility matrix to avoid recomputing later on\n",
    "    # loss = CategoricalCrossentropy()\n",
    "    loss = KLDivergence()\n",
    "else:\n",
    "    Z = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1234]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Atari environment\n",
    "env = gym.make('SpaceInvadersDeterministic-v4')\n",
    "\n",
    "# Set seeds\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging and storage\n",
    "# model_name = 'DQN_cp_4f_50ri_3n_pr_cf_tf7_cc_dd_pp3_ds'\n",
    "model_name = 'dn_test'\n",
    "model_dir = f'../{game}/model/{model_name}'\n",
    "\n",
    "os.mkdir(model_dir)\n",
    "os.mkdir(model_dir + '/record')\n",
    "os.mkdir(model_dir + '/model')\n",
    "\n",
    "opath_mem = f'{model_dir}/replay_mem.pkl'\n",
    "opath_model = f'{model_dir}/model/model.keras'\n",
    "ep_log = EpisodeLogger(model_dir + '/episode_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = range(6)  # Use default action space https://www.gymlibrary.dev/environments/atari/space_invaders/\n",
    "M = len(action_space)\n",
    "kernel_init = 'he_normal'\n",
    "\n",
    "# Set frame crop configuration\n",
    "env.reset()\n",
    "frame = env.step(1)[0]\n",
    "crop_lims = FRAME_CROP_SETTINGS[game] if crop_frame else None\n",
    "frame_shape = preprocess_frame_v4(frame, crop_lims).shape\n",
    "state_shape = (*frame_shape, state_len)\n",
    "\n",
    "# Initialize behavioral network\n",
    "# If using dueling net, we use a seperate action model to back out V and A streams efficiently\n",
    "# Note that this model is clone of behavioral model and points to the same underlying layers\n",
    "if duel_net:\n",
    "    model = atari_model_dueling(M, lr, state_shape, kernel_init, noisy_net, large_net)\n",
    "    model_action = tf.keras.Model(\n",
    "        inputs=[model.get_layer('input_frames').input], \n",
    "        outputs=[model.get_layer('V').output, model.get_layer('A_adj').output]\n",
    "    )\n",
    "elif distr_net:\n",
    "    model = atari_model_distr(N, M, loss, lr, state_shape, kernel_init, noisy_net)\n",
    "    model_action = model\n",
    "else:\n",
    "    model = atari_model(M, lr, state_shape, kernel_init, noisy_net, large_net)\n",
    "    model_action = model\n",
    "\n",
    "# Initialize target network\n",
    "model_tgt = clone_model(model)\n",
    "model_tgt.set_weights(model.get_weights())\n",
    "\n",
    "# Initialize replay memory\n",
    "replay_mem = PrioritizedReplayMemory(replay_mem_sz, state_len, n_step, per_alpha, per_beta)\n",
    "frame_num = 0\n",
    "max_episode_reward = 0\n",
    "episode_start = 0\n",
    "init_done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=False, show_layer_activations=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../script/utils.py:146: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(np.max(Qs, axis=1)),\n",
      "/Users/dionjoren/opt/anaconda3/envs/tf-pip-cp-2.12.0/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/dionjoren/opt/anaconda3/envs/tf-pip-cp-2.12.0/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/dionjoren/opt/anaconda3/envs/tf-pip-cp-2.12.0/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "2024-02-02 00:51:22.029960: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ce3f04d0-3e05-474b-a126-1855318a47e4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dionjoren/opt/anaconda3/envs/tf-pip-cp-2.12.0/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/Users/dionjoren/opt/anaconda3/envs/tf-pip-cp-2.12.0/lib/python3.8/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "../script/utils.py:146: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(np.max(Qs, axis=1)),\n",
      "/Users/dionjoren/opt/anaconda3/envs/tf-pip-cp-2.12.0/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/dionjoren/opt/anaconda3/envs/tf-pip-cp-2.12.0/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "../script/replay_memory.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([self.get_memory(idx, n) for idx in idxs]).T\n"
     ]
    }
   ],
   "source": [
    "mp_pool = mp.Pool(1)\n",
    "t_lastmax = datetime.now()  # Time since last max train score (controls)\n",
    "i_animation = 0  # Used to toggle between saliency types\n",
    "\n",
    "for episode_num in range(episode_start, total_train_len):\n",
    "    # Start a new game (episode)\n",
    "    init_frame = env.reset()\n",
    "    new_life = True\n",
    "    game_over = False\n",
    "\n",
    "    # Keep track of episode figures\n",
    "    episode_reward = 0\n",
    "    episode_train_cnt = 0\n",
    "    episode_frames = []\n",
    "    episode_states = []\n",
    "    episode_actions = []\n",
    "    episode_Qs = []\n",
    "    episode_Vs = []\n",
    "    episode_As = []\n",
    "    episode_pZs = []\n",
    "    episode_losses = []\n",
    "    episode_tderrs = []\n",
    "\n",
    "    # SI specific: skip first 20 frames when new game (40 in total with new-life line)\n",
    "    for _ in range(20):\n",
    "        env.step(0)\n",
    "\n",
    "    # Play episode until game over\n",
    "    while not game_over:\n",
    "        if new_life:\n",
    "            # SI specific: skip first 20 frames when new life\n",
    "            for _ in range(20):\n",
    "                env.step(0)\n",
    "\n",
    "            for _ in range(random.randint(1, 15)):\n",
    "                # Random initialization, to reduce overfitting\n",
    "                frame, _, game_over, info = env.step(sample_ran_action(action_space))\n",
    "            \n",
    "            lives = info['ale.lives']\n",
    "            frame_pp = preprocess_frame_v4(frame, crop_lims)  # Maxpooling not needed for first frame\n",
    "            state = np.stack(state_len * [frame_pp], axis=2)\n",
    "            \n",
    "        # Select action\n",
    "        eps = get_lin_anneal_eps(frame_num - replay_init_sz, eps_init, eps_final, eps_final_frame)\n",
    "        eps = eps if init_done else 1\n",
    "        action, Q, V, A, pZ = choose_action(\n",
    "            model_action, state, action_space, eps, duel_net, distr_net, Z\n",
    "        )\n",
    "        \n",
    "        # Store state and actions variables\n",
    "        episode_frames.append(frame)\n",
    "        episode_states.append(state)\n",
    "        episode_actions.append(action)\n",
    "        episode_Qs.append(Q)\n",
    "        episode_Vs.append(V)\n",
    "        episode_As.append(A)\n",
    "        episode_pZs.append(pZ)\n",
    "        \n",
    "        # Take action and observe transition\n",
    "        prev_frame = frame  # Keep previous frame for max pooling step\n",
    "        frame, reward, game_over, info = env.step(action)\n",
    "        \n",
    "        # Process env response\n",
    "        frame_pp = frame_max_pooling([prev_frame, frame])\n",
    "        frame_pp = preprocess_frame_v4(frame_pp, crop_lims)\n",
    "        state = np.append(state[:, :, 1:], frame_pp[:, :, None], axis=2)\n",
    "        # reward = clip_reward(reward)\n",
    "        new_life = info['ale.lives'] < lives \n",
    "        lives = info['ale.lives']\n",
    "        \n",
    "        # Add new transition to replay memory\n",
    "        transition = (action, reward, game_over or new_life, new_life, frame_pp)  # TODO: inspect game + life\n",
    "        replay_mem.store_memory(transition)\n",
    "                \n",
    "        # Increase transition counters\n",
    "        frame_num += 1\n",
    "        episode_reward += reward\n",
    "        init_done = frame_num >= replay_init_sz  # Is replay initializing done\n",
    "                    \n",
    "        # After init period start replay transitions and train model\n",
    "        if init_done:\n",
    "            \n",
    "            # # Initialize td-errors of init replay mems\n",
    "            # if init_tds and frame_num == replay_init_sz:\n",
    "            #     replay_init_idxs = range(replay_init_sz)\n",
    "            #     replay_init_ps = replay_mem.get_priorities(replay_init_idxs)\n",
    "            #     replay_init_idxs = np.flatnonzero(replay_init_ps)\n",
    "            #     replay_init_mems = replay_mem.get_memories(replay_init_idxs, n_step)[:-1]\n",
    "            #     replay_init_td_errs = td_error(model, model_tgt, action_space, disc_rate, *replay_init_mems)\n",
    "            #     replay_mem.update_priorities(replay_init_idxs, replay_init_td_errs)\n",
    "\n",
    "            # Train model every train_interval\n",
    "            if frame_num % train_interval == 0:\n",
    "                mini_batch = replay_mem.get_sample(batch_sz)\n",
    "                batch_idxs, mini_batch = mini_batch[-1], mini_batch[:-1]\n",
    "                w_imps = replay_mem.get_imps_weights(batch_idxs)\n",
    "                \n",
    "                if distr_net:\n",
    "                    batch_td_errs, loss = fit_batch_DDQNn_PER_DS(\n",
    "                        model, model_tgt, action_space, disc_rate, *mini_batch, w_imps, \n",
    "                        Z, Z_repN, dZ, (V_min, V_max), noisy_net, double_learn\n",
    "                    )\n",
    "                else:\n",
    "                    batch_td_errs, loss = fit_batch_DDQNn_PER(\n",
    "                        model, model_tgt, action_space, disc_rate, *mini_batch, \n",
    "                        w_imps, noisy_net, double_learn\n",
    "                    )\n",
    "                replay_mem.update_priorities(batch_idxs, batch_td_errs)\n",
    "                # Is there balance between updating ps and having new ps set to max? will updated ps stand a chance?\n",
    "                episode_train_cnt += 1\n",
    "                episode_losses.append(loss)\n",
    "                episode_tderrs.append(np.mean(batch_td_errs))\n",
    "\n",
    "            # Update target model\n",
    "            if frame_num % tgt_update_interval == 0:\n",
    "                model_tgt.set_weights(model.get_weights())\n",
    "\n",
    "    # Log episode statistics\n",
    "    ep_log.append(\n",
    "        episode_num, episode_train_cnt, frame_num, episode_reward, \n",
    "        episode_actions, episode_Qs, episode_losses, episode_tderrs\n",
    "    )\n",
    "\n",
    "    # Variables to control output frequency\n",
    "    run_anim_reg = episode_num % 1000 == 0\n",
    "    run_anim_max = (episode_reward > max_episode_reward) & (datetime.now() > t_lastmax)\n",
    "    backup_model = episode_num % 250 == 0\n",
    "\n",
    "    # Output episode animation video every 1000 episodes\n",
    "    # Also output episode video if new max score was attained, and time-delta has been met\n",
    "    if run_anim_reg or run_anim_max:\n",
    "        opath_anim = f'{model_dir}/record/{episode_num}_train_{episode_reward}.mp4'\n",
    "        sal_type = 'gcam' if i_animation % 2 else 'sal'\n",
    "\n",
    "        mp_pool.apply_async(animate_episode_sal, args=(\n",
    "            model, episode_states, episode_frames, episode_actions, \n",
    "            episode_Qs, episode_Vs, episode_As, action_space, opath_anim, \n",
    "            duel_net, distr_net, (Z, episode_pZs), sal_type)\n",
    "        )\n",
    "        i_animation += 1\n",
    "        if run_anim_max:\n",
    "            t_lastmax = datetime.now() + timedelta(minutes=30)\n",
    "            max_episode_reward = episode_reward\n",
    "        \n",
    "    # Backup model and replay memory every 250 episodes\n",
    "    # Note: takes a minute or two, so should not be run frequently \n",
    "    if backup_model:\n",
    "        joblib.dump(replay_mem, opath_mem, compress=3)\n",
    "        model.save(opath_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # Somehow this causes y_pred to have slightly different decimals\n",
    "def train_on_batch(model, x, y_tgt, actions, tgt_zeroing=False, sample_weight=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass, keep only pred values for actions actually taken\n",
    "        y_pred = model(x, training=True)\n",
    "        indices = tf.expand_dims(actions, -1)  # 1D to 2D\n",
    "        y_pred = tf.expand_dims(tf.gather_nd(y_pred, indices, batch_dims=1), -1)\n",
    "        loss = model.loss(y_tgt, y_pred, sample_weight=sample_weight)\n",
    "        \n",
    "    # Backward pass\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss\n",
    "\n",
    "@tf.function  # Somehow this causes y_pred to have slightly different decimals\n",
    "def train_on_batch2(model, x, y_tgt, actions, tgt_zeroing=False, sample_weight=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "\n",
    "        # Set target such that updates are only executed for those actions taken,\n",
    "        # i.e. one action per each sample\n",
    "        shape = y_pred.get_shape()\n",
    "        indices = tf.stack([tf.range(shape[0]), actions], axis=1)\n",
    "        if tgt_zeroing:\n",
    "            y_tgt = tf.scatter_nd(indices, y_tgt, shape)  # Set all but the update values to 0\n",
    "        else:\n",
    "            y_tgt = tf.tensor_scatter_nd_update(y_pred, indices, y_tgt)  # Set all but the update values to y_pred\n",
    "        loss = model.loss(y_tgt, y_pred, sample_weight=sample_weight)\n",
    "        \n",
    "    # Backward pass\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss\n",
    "\n",
    "from atari_model import abs_td_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_now, action, rewards, game_over, state_next = mini_batch\n",
    "x = np.stack(state_now)\n",
    "action = action.astype('int32')\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "model1 = atari_model_dueling(M, lr, state_shape, kernel_init, noisy_net, large_net)\n",
    "tf.random.set_seed(seed)\n",
    "model2 = atari_model_dueling(M, lr, state_shape, kernel_init, noisy_net, large_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_next_tgt = model1(x).numpy()\n",
    "Q_next_tgt_max = Q_next_tgt.max(axis=1, keepdims=True)\n",
    "n = 3\n",
    "R_n = (np.stack(rewards)).sum(axis=1, keepdims=True)  # n-step forward return\n",
    "Q_now_tgt = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)\n",
    "pred1, l1 = train_on_batch(model1, x, Q_now_tgt, action, sample_weight=w_imps)\n",
    "td1 = abs_td_error(pred1, Q_now_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_next_tgt = model1(x).numpy()\n",
    "Q_next_tgt_max = Q_next_tgt.max(axis=1, keepdims=True)\n",
    "n = 3\n",
    "R_n = (np.stack(rewards)).sum(axis=1, keepdims=True)  # n-step forward return\n",
    "Q_now_tgt = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_next_tgt = model1(x).numpy()\n",
    "Q_next_tgt_max = Q_next_tgt.max(axis=1)\n",
    "n = 3\n",
    "R_n = (np.stack(rewards)).sum(axis=1)  # n-step forward return\n",
    "Q_now_tgt2 = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16592658,  0.06072769,  0.09493752,  0.16158016,  0.05259099,\n",
       "        0.10843253,  0.23562898,  0.16574259,  0.0614053 ,  0.05316041,\n",
       "       -0.09435908,  0.13099879,  0.09184173,  0.21896473,  0.26399025,\n",
       "        0.17539315,  0.19559202,  0.10241026,  0.11359905,  0.10644329,\n",
       "        0.19914463,  0.09802823,  0.07264499,  0.2231821 ,  0.11533904,\n",
       "        0.14305255,  0.10845242,  0.11606859,  0.16778196,  0.04622375,\n",
       "        0.09634934,  0.199819  ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_next_tgt[range(32),Q_next_tgt.argmax(axis=1), None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 1), (32,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_now_tgt.shape, Q_now_tgt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_now_tgt2 == Q_now_tgt.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(model, x, y_tgt, actions, tgt_zeroing=False, sample_weight=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass, keep only pred values for actions actually taken\n",
    "        y_pred = model(x, training=True)\n",
    "        indices = tf.expand_dims(actions, -1)  # 1D to 2D\n",
    "        y_pred = tf.expand_dims(tf.gather_nd(y_pred, indices, batch_dims=1), -1)\n",
    "        # y_pred = tf.gather_nd(y_pred, indices, batch_dims=1)\n",
    "        loss = Huber(reduction='auto')(y_tgt, y_pred, sample_weight=sample_weight)\n",
    "        # loss = model.loss(y_tgt, y_pred) / 6\n",
    "    return loss, y_pred\n",
    "\n",
    "def f11(model, x, y_tgt, actions, tgt_zeroing=False, sample_weight=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        indices = tf.expand_dims(actions, -1)  # 1D to 2D\n",
    "        y_pred = tf.expand_dims(tf.gather_nd(y_pred, indices, batch_dims=1), -1)\n",
    "        loss = Huber()(y_tgt, y_pred, sample_weight=sample_weight) / 6\n",
    "    return loss, y_pred\n",
    "\n",
    "def f2(model, x, y_tgt, actions, sample_weight=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass, keep only pred values for actions actually taken\n",
    "        y_pred = model(x, training=True)\n",
    "        shape = y_pred.get_shape()\n",
    "        indices = tf.stack([tf.range(shape[0]), actions], axis=1)\n",
    "        y_tgt = tf.tensor_scatter_nd_update(y_pred, indices, y_tgt)  # Set all but the update values to y_pred\n",
    "        loss = Huber(reduction='auto')(y_tgt, y_pred, sample_weight=sample_weight)\n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2136731, 1.2136731147766113)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    f1(model, x, Q_now_tgt, action, sample_weight=w_imps)[0].numpy().mean(),\n",
    "    f2(model, x, Q_now_tgt2, action, sample_weight=w_imps)[0].numpy().mean() * 6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.20227885>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.20227885>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    f1(model, x, Q_now_tgt, action, sample_weight=w_imps)[0] / 6,\n",
    "    f2(model, x, Q_now_tgt2, action, sample_weight=w_imps)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20227885246276855,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.20227885>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.20227885>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    np.mean(f1(model, x, Q_now_tgt, action, sample_weight=w_imps)[0]) / 6,\n",
    "    f11(model, x, Q_now_tgt, action, sample_weight=w_imps)[0],\n",
    "    f2(model, x, Q_now_tgt2, action, sample_weight=w_imps)[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.61145270e-01],\n",
       "       [ 2.14669779e-02],\n",
       "       [ 1.51709528e+01],\n",
       "       [ 2.03712583e-02],\n",
       "       [ 7.61484280e-02],\n",
       "       [ 1.24149077e-01],\n",
       "       [-2.64927745e-04],\n",
       "       [ 7.15637766e-03],\n",
       "       [ 1.24165490e-01],\n",
       "       [ 1.84970409e-01],\n",
       "       [ 2.32546568e-01],\n",
       "       [ 8.24995190e-02],\n",
       "       [ 1.99180454e-01],\n",
       "       [-4.14049998e-02],\n",
       "       [ 9.58715081e-02],\n",
       "       [ 3.31913888e-01],\n",
       "       [ 2.30275244e-01],\n",
       "       [-1.04053795e-01],\n",
       "       [ 1.69075131e-01],\n",
       "       [ 1.46381915e-01],\n",
       "       [ 8.78487974e-02],\n",
       "       [ 3.02403030e+01],\n",
       "       [ 1.76405251e-01],\n",
       "       [ 1.73055053e-01],\n",
       "       [ 8.26931596e-02],\n",
       "       [ 2.72347212e-01],\n",
       "       [ 6.14454076e-02],\n",
       "       [-1.06498674e-02],\n",
       "       [ 9.83160138e-02],\n",
       "       [ 4.20964956e-02],\n",
       "       [ 2.38716155e-02],\n",
       "       [ 6.01409897e-02]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_now_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.23136456>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.23083226>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.stack(state_now)\n",
    "l1, y1 = f1(model, x, Q_now_tgt2, action)\n",
    "l2, y2 = f1(model, x, Q_now_tgt, action)\n",
    "l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.23083226>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.23083226>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.stack(state_now)\n",
    "l1, y1 = f1(model, x, Q_now_tgt, action, sample_weight=w_imps[:, None])\n",
    "l2, y2 = f1(model, x, Q_now_tgt, action, sample_weight=w_imps)\n",
    "l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(y1 == y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.3849936>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3881874>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(Q_now_tgt, y1), model.loss(Q_now_tgt2, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12501681e-01],\n",
       "       [-7.45910034e-02],\n",
       "       [ 1.50615225e+01],\n",
       "       [ 1.90830100e-02],\n",
       "       [-9.80816111e-02],\n",
       "       [-6.57125637e-02],\n",
       "       [-1.47648066e-01],\n",
       "       [-1.10246770e-01],\n",
       "       [-1.43623993e-01],\n",
       "       [-1.27182752e-01],\n",
       "       [-3.51558328e-02],\n",
       "       [-3.75804380e-02],\n",
       "       [-1.18977040e-01],\n",
       "       [-1.00912228e-01],\n",
       "       [-1.54760629e-01],\n",
       "       [-5.00906706e-02],\n",
       "       [ 2.04010308e-03],\n",
       "       [-5.47601953e-02],\n",
       "       [-5.23475409e-02],\n",
       "       [-2.22518742e-02],\n",
       "       [-4.08160239e-02],\n",
       "       [ 3.01076927e+01],\n",
       "       [-1.92460716e-02],\n",
       "       [-8.39561224e-03],\n",
       "       [-1.54348016e-01],\n",
       "       [ 2.75989383e-01],\n",
       "       [-5.02593294e-02],\n",
       "       [-4.67834175e-02],\n",
       "       [-1.42308667e-01],\n",
       "       [-8.12738985e-02],\n",
       "       [-6.35515302e-02],\n",
       "       [-2.19991803e-02]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q_now_tgt - y1).numpy()#, (Q_now_tgt2 - y1).numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11250168, -0.25217998, 14.8973055 , ..., -0.23155046,\n",
       "        -0.24977534, -0.21350595],\n",
       "       [ 0.06508729, -0.074591  , 15.074895  , ..., -0.05396149,\n",
       "        -0.07218637, -0.03591699],\n",
       "       [ 0.05171499, -0.08796331, 15.0615225 , ..., -0.06733379,\n",
       "        -0.08555867, -0.04928929],\n",
       "       ...,\n",
       "       [ 0.03777488, -0.10190342, 15.047583  , ..., -0.0812739 ,\n",
       "        -0.09949878, -0.0632294 ],\n",
       "       [ 0.07372212, -0.06595617, 15.083529  , ..., -0.04532665,\n",
       "        -0.06355153, -0.02728216],\n",
       "       [ 0.0790051 , -0.06067319, 15.088813  , ..., -0.04004367,\n",
       "        -0.05826855, -0.02199918]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q_now_tgt2 - y1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.02156162e+01, 2.25859314e-01, 1.21854492e-01, 3.39083374e-03,\n",
       "       3.04274231e-01, 3.09470028e-01, 1.36214793e-01, 2.88032115e-01,\n",
       "       2.51581612e+01, 4.84219566e-02, 1.15301386e-01, 2.02334061e-01,\n",
       "       1.50000000e+01, 3.01987228e+01, 1.50000000e+01, 5.26766300e+00,\n",
       "       2.00197334e+01, 1.39158517e-01, 1.60349786e-01, 1.50000000e+01,\n",
       "       1.30929261e-01, 0.00000000e+00, 2.20590476e-02, 2.03035984e+01,\n",
       "       1.18493751e-01, 5.38515568e+00, 3.09257656e-01, 5.21540642e-08,\n",
       "       2.02161064e+01, 2.12894157e-01, 2.31461108e-01, 4.33051765e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Q_next_tgt \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m(x)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m Q_next_tgt_max \u001b[38;5;241m=\u001b[39m Q_next_tgt\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "Q_next_tgt = model2(x).numpy()\n",
    "Q_next_tgt_max = Q_next_tgt.max(axis=1, keepdims=False)\n",
    "n = 3\n",
    "R_n = (np.stack(rewards)).sum(axis=1, keepdims=False)  # n-step forward return\n",
    "Q_now_tgt = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)\n",
    "pred2, l2 = train_on_batch2(model2, x, Q_now_tgt, action, sample_weight=w_imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.02156162e+01, 2.25859314e-01, 1.21854492e-01, 3.39083374e-03,\n",
       "       3.04274231e-01, 3.09470028e-01, 1.36214793e-01, 2.88032115e-01,\n",
       "       2.51581612e+01, 4.84219566e-02, 1.15301386e-01, 2.02334061e-01,\n",
       "       1.50000000e+01, 3.01987228e+01, 1.50000000e+01, 5.26766300e+00,\n",
       "       2.00197334e+01, 1.39158517e-01, 1.60349786e-01, 1.50000000e+01,\n",
       "       1.30929261e-01, 0.00000000e+00, 2.20590476e-02, 2.03035984e+01,\n",
       "       1.18493751e-01, 5.38515568e+00, 3.09257656e-01, 5.21540642e-08,\n",
       "       2.02161064e+01, 2.12894157e-01, 2.31461108e-01, 4.33051765e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td2 = abs_td_error(pred2.numpy()[range(batch_sz), action] , Q_now_tgt)\n",
    "td2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.135637, shape=(), dtype=float32)\n",
      "tf.Tensor(6.127363, shape=(), dtype=float32)\n",
      "tf.Tensor(6.121019, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1173587, shape=(), dtype=float32)\n",
      "tf.Tensor(6.117865, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1197133, shape=(), dtype=float32)\n",
      "tf.Tensor(6.124042, shape=(), dtype=float32)\n",
      "tf.Tensor(6.130021, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1377068, shape=(), dtype=float32)\n",
      "tf.Tensor(6.150482, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1717005, shape=(), dtype=float32)\n",
      "tf.Tensor(6.2066145, shape=(), dtype=float32)\n",
      "tf.Tensor(6.2594137, shape=(), dtype=float32)\n",
      "tf.Tensor(6.335909, shape=(), dtype=float32)\n",
      "tf.Tensor(6.4283876, shape=(), dtype=float32)\n",
      "tf.Tensor(6.522491, shape=(), dtype=float32)\n",
      "tf.Tensor(6.6542797, shape=(), dtype=float32)\n",
      "tf.Tensor(6.8238497, shape=(), dtype=float32)\n",
      "tf.Tensor(7.098086, shape=(), dtype=float32)\n",
      "tf.Tensor(7.4091024, shape=(), dtype=float32)\n",
      "tf.Tensor(8.271431, shape=(), dtype=float32)\n",
      "tf.Tensor(8.68379, shape=(), dtype=float32)\n",
      "tf.Tensor(12.808443, shape=(), dtype=float32)\n",
      "tf.Tensor(12.775448, shape=(), dtype=float32)\n",
      "tf.Tensor(19.297365, shape=(), dtype=float32)\n",
      "tf.Tensor(17.024376, shape=(), dtype=float32)\n",
      "tf.Tensor(29.378645, shape=(), dtype=float32)\n",
      "tf.Tensor(33.4597, shape=(), dtype=float32)\n",
      "tf.Tensor(49.205215, shape=(), dtype=float32)\n",
      "tf.Tensor(49.933884, shape=(), dtype=float32)\n",
      "tf.Tensor(79.90632, shape=(), dtype=float32)\n",
      "tf.Tensor(75.123314, shape=(), dtype=float32)\n",
      "tf.Tensor(119.80838, shape=(), dtype=float32)\n",
      "tf.Tensor(148.24081, shape=(), dtype=float32)\n",
      "tf.Tensor(180.44879, shape=(), dtype=float32)\n",
      "tf.Tensor(173.78082, shape=(), dtype=float32)\n",
      "tf.Tensor(239.31976, shape=(), dtype=float32)\n",
      "tf.Tensor(255.141, shape=(), dtype=float32)\n",
      "tf.Tensor(359.44873, shape=(), dtype=float32)\n",
      "tf.Tensor(424.53552, shape=(), dtype=float32)\n",
      "tf.Tensor(491.8224, shape=(), dtype=float32)\n",
      "tf.Tensor(534.5034, shape=(), dtype=float32)\n",
      "tf.Tensor(657.4696, shape=(), dtype=float32)\n",
      "tf.Tensor(686.6982, shape=(), dtype=float32)\n",
      "tf.Tensor(846.11865, shape=(), dtype=float32)\n",
      "tf.Tensor(920.3286, shape=(), dtype=float32)\n",
      "tf.Tensor(1131.5684, shape=(), dtype=float32)\n",
      "tf.Tensor(1222.1517, shape=(), dtype=float32)\n",
      "tf.Tensor(1421.2395, shape=(), dtype=float32)\n",
      "tf.Tensor(1555.1528, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    Q_next_tgt = model1(x).numpy()\n",
    "    Q_next_tgt_max = Q_next_tgt.max(axis=1, keepdims=True)\n",
    "    n = 3\n",
    "    R_n = (np.stack(rewards)).sum(axis=1, keepdims=True)  # n-step forward return\n",
    "    Q_now_tgt = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)\n",
    "    print(train_on_batch(model1, x, Q_now_tgt, action, sample_weight=w_imps)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.146886, shape=(), dtype=float32)\n",
      "tf.Tensor(6.144699, shape=(), dtype=float32)\n",
      "tf.Tensor(6.142667, shape=(), dtype=float32)\n",
      "tf.Tensor(6.140784, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1390414, shape=(), dtype=float32)\n",
      "tf.Tensor(6.137376, shape=(), dtype=float32)\n",
      "tf.Tensor(6.135777, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1342688, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1328516, shape=(), dtype=float32)\n",
      "tf.Tensor(6.13151, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1302347, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1289864, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1278276, shape=(), dtype=float32)\n",
      "tf.Tensor(6.12673, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1257033, shape=(), dtype=float32)\n",
      "tf.Tensor(6.124819, shape=(), dtype=float32)\n",
      "tf.Tensor(6.124154, shape=(), dtype=float32)\n",
      "tf.Tensor(6.123536, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1231728, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1228895, shape=(), dtype=float32)\n",
      "tf.Tensor(6.122612, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1223927, shape=(), dtype=float32)\n",
      "tf.Tensor(6.122241, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1223474, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1228113, shape=(), dtype=float32)\n",
      "tf.Tensor(6.123371, shape=(), dtype=float32)\n",
      "tf.Tensor(6.124154, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1250916, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1260467, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1271253, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1283283, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1296654, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1310534, shape=(), dtype=float32)\n",
      "tf.Tensor(6.132521, shape=(), dtype=float32)\n",
      "tf.Tensor(6.134121, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1358657, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1376424, shape=(), dtype=float32)\n",
      "tf.Tensor(6.139705, shape=(), dtype=float32)\n",
      "tf.Tensor(6.142166, shape=(), dtype=float32)\n",
      "tf.Tensor(6.14505, shape=(), dtype=float32)\n",
      "tf.Tensor(6.148555, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1528225, shape=(), dtype=float32)\n",
      "tf.Tensor(6.157773, shape=(), dtype=float32)\n",
      "tf.Tensor(6.163291, shape=(), dtype=float32)\n",
      "tf.Tensor(6.169732, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1773276, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1857476, shape=(), dtype=float32)\n",
      "tf.Tensor(6.195345, shape=(), dtype=float32)\n",
      "tf.Tensor(6.206128, shape=(), dtype=float32)\n",
      "tf.Tensor(6.218396, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    Q_next_tgt = model2(x).numpy()\n",
    "    Q_next_tgt_max = Q_next_tgt.max(axis=1, keepdims=False)\n",
    "    n = 3\n",
    "    R_n = (np.stack(rewards)).sum(axis=1, keepdims=False)  # n-step forward return\n",
    "    Q_now_tgt = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)\n",
    "    print(train_on_batch2(model2, x, Q_now_tgt, action, sample_weight=w_imps)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.5 - 3 compr GB for 4508 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # Somehow this causes y_pred to have slightly different decimals\n",
    "def train_on_batch(model, x, y_tgt, actions, tgt_zeroing=False, sample_weight=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass, keep only pred values for actions actually taken\n",
    "        y_pred = model(x, training=True)\n",
    "        indices = tf.expand_dims(actions, -1)  # 1D to 2D\n",
    "        y_pred = tf.expand_dims(tf.gather_nd(y_pred, indices, batch_dims=1), -1)\n",
    "        loss = model.loss(y_tgt, y_pred, sample_weight=sample_weight)\n",
    "        \n",
    "    # Backward pass\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_now, action, rewards, game_over, state_next = mini_batch\n",
    "x = np.stack(state_now)\n",
    "action = action.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_tgt = clone_model(model)\n",
    "# model_tgt.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
       " array([[1.0627561 ],\n",
       "        [0.8938535 ],\n",
       "        [0.6220055 ],\n",
       "        [0.4317693 ],\n",
       "        [0.63995767],\n",
       "        [1.0317239 ],\n",
       "        [0.48084933],\n",
       "        [0.692519  ],\n",
       "        [0.70803404],\n",
       "        [0.49818942],\n",
       "        [0.8305197 ],\n",
       "        [1.0515336 ],\n",
       "        [0.95167315],\n",
       "        [0.93536884],\n",
       "        [0.88220966],\n",
       "        [0.82973146],\n",
       "        [0.543817  ],\n",
       "        [0.8471759 ],\n",
       "        [0.74581546],\n",
       "        [0.7531091 ],\n",
       "        [0.70619166],\n",
       "        [0.97358567],\n",
       "        [0.36639675],\n",
       "        [0.7019837 ],\n",
       "        [0.5633619 ],\n",
       "        [0.7633652 ],\n",
       "        [0.57345474],\n",
       "        [0.7209159 ],\n",
       "        [0.99736494],\n",
       "        [0.8776028 ],\n",
       "        [0.9415817 ],\n",
       "        [0.6316835 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.102832>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_next_tgt = model(x).numpy()\n",
    "Q_next_tgt_max = Q_next_tgt.max(axis=1, keepdims=True)\n",
    "n = 3\n",
    "R_n = (np.stack(rewards)).sum(axis=1, keepdims=True)  # n-step forward return\n",
    "Q_now_tgt = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)\n",
    "train_on_batch(model, x, Q_now_tgt, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = model(np.stack(state_next)).numpy()[:, 0].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_next_tgt = model(np.stack(state_next)).numpy()\n",
    "Q_next_tgt_max = Q_next_tgt.max(axis=1, keepdims=True)\n",
    "\n",
    "# Set Q target. We only want to run SGD updates for those actions taken\n",
    "n = 3\n",
    "R_n = (np.stack(rewards)).sum(axis=1, keepdims=True)  # n-step forward return\n",
    "Q_now_tgt = np.float32(R_n + Q_next_tgt_max)  # Has dims (batch_sz, 1)\n",
    "Q_now_tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [30.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [20.],\n",
       "       [ 0.],\n",
       "       [ 0.]], dtype=float16)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_n[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # Somehow this causes y_pred to have slightly different decimals\n",
    "def train_on_batch(model, x, y_tgt, actions, tgt_zeroing=False, sample_weight=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass, keep only pred values for actions actually taken\n",
    "        y_pred = model(x, training=True)\n",
    "        indices = tf.stack([tf.range(y_pred.get_shape()[0]), actions], axis=1)\n",
    "        y_pred = tf.gather_nd(y_pred, indices)\n",
    "        print(y_pred.shape, y_tgt.shape, len(sample_weight))\n",
    "        loss = model.loss(y_tgt, y_pred, sample_weight=sample_weight)\n",
    "        \n",
    "    # Backward pass\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
